## 1.训练结果的理解

### (1)训练的文件

> 1.weights
>
> 训练好的模型，包括best.pt和last.pt
>
> 2.confusion_matrix.png
>
> 混淆矩阵
>
> 3.F1_curve.png
>
> 精确率和召回率的调和平均数
>
> 4.P_curve.png
>
> 准确率和置信度的关系图
>
> 5.PR_curve.png
>
> 精确率与召回率的关系
>
> 6.R_curve.png
>
> 召回率和置信度之间的关系
>
> 7.results.png
>
> 8.results.txt
>
> 9.train_batchx

### （2）具体理解

> （1）confusion_matrix.png（混淆矩阵）
>
> ​	以矩阵形式将数据集中的记录按照真实的类别与分类模型预测的类别判断两个标准进行汇总。其中矩阵的行表示真实值，矩阵的列表示预测值
>
> （2）F1_curve.png
>
> ​	精确率和召回率的调和平均数
>
> （3）P_curve.png
>
> ​	准确率和置信度的关系图
>
> （4）arg.yaml
>
> ​	训练时的超参数以及train.py中间的参数
>
> （5）P_curve.png
>
> ​	准确率和置信度的关系图
>
> （6）PR_curve.png
>
> ​	准确率和召回率的关系图
>
> （7）R_curve.png
>
> ​	召回率和置信度的关系图
>
> （8）results.png
>
> ​	1.box：box推测损失函数均值
>
> ​	2.cls：推测为目标检测loss均值
>
> ​	3.dfl：目标检测边界框回归精度的损失函数均值
>
> ​	4.precision:君度
>
> ​	5.recall：准确率
>
> ​	6.mAP：时用Precision和Recall作为两周作图后围城的面积，m表示平均。后面的数据表示均值
>
> > > 注意：
> > >
> > > cls_loss：当分类损失<0.1时，比较好
> > >
> > > box_loss：当0.01-0.1之间比较好
>
> （9）results.txt
>
> 训练集的各种具体数据

---

## 2.参数的使用

> AI框架会在合理范围内自己造数据，这一步操作叫“图片增强”
>
> 1.fliplr
>
> ​	图像左右翻转的概率
>
> > > > 注意：
> > > >
> > > > fliplr=0.5表示在数据增强阶段，每张图像都有50%的概率会进行水平翻转
>
> 2.Mosaic
>
> ​	将四张图像拼接成一张图像（可以提供更多的上下文和更多的目标实例）
>
> 工作原理：
>
> ​	（1）图像拼接
>
> ​	（2）随机裁剪和缩放
>
> ​	（3）标签调整
>
> 3.batch
>
> ​	一次训练多少张图片
>
> ​	就是在result文件中的batch后缀图片。如果是4行4列共16格子的图片，那batch就是16
>
> > > 注意：如果使用CPU进行训练，batch的大小印象的是RAM（内存），如果使用GPU进行训练，那么批次大小影响的是显存
>
> 4.workers
>
> ​	设置数据加载时的工作线程数（并行加载数据的进程数）
>
> ​	每个worker线程会占用一个CPU核心

---

## 3.实用的技巧

> 1.对镜像图像的处理
>
> 在使用yolo检测后，马上使用cv.flip对图像进行翻转，示例：
>
> ```
> ret, frame = cap.read()
> if not ret:
>  print("无法接收帧")
>  break
> 
> results = yolo(source=frame, verbose=False, conf=0.35)[0]
> 
> # 先对图像进行翻转
> flipped_frame = cv.flip(frame, 1)
> ```

> 2.YOLO训练的中途停止
>
> （1）中断
>
> 再命令行界面运行时，按ctrl + C可立即终止训练进程
>
> （2）恢复
>
> 设置resume参数为True,然后指定last.pt文件，示例：
>
> from ultralytics import YOLO
> model = YOLO("path/to/last.pt")
>
> results = model.train()
>
> ​	直接用last.pt来进行训练就相当于从中断的位置进行重新开始训练（默认给你重新训练100次）
>
> 3.提醒
>
> ​	在终端中会显示验证集的图片检测结果，到差不多的时候直接ctrl+c卡断
>
> 4.转换格式
>
> ```
> from ultralytics import YOLO
> 
> model =YOLO(model="path")
> 
> model.export(format="onnx")
> ```
